{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries for analysis\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import (FunctionTransformer, Normalizer, OneHotEncoder, StandardScaler, normalize, scale)\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import  plot_confusion_matrix, classification_report\n",
    "\n",
    "# setting random state to have reproducible results\n",
    "random_state=12\n",
    "\n",
    "# read in data\n",
    "patient_data = pd.read_csv(\"data/ehr_data.csv\")\n",
    "\n",
    "# splitting data into train and test splits\n",
    "patient_train, patient_test = train_test_split(patient_data, test_size=0.2, random_state=12, stratify=patient_data[\"SOURCE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate feature vectors from target\n",
    "X_train = patient_train.drop(columns = [\"SOURCE\"])\n",
    "y_train = patient_train[\"SOURCE\"]\n",
    "X_test = patient_test.drop(columns = [\"SOURCE\"])\n",
    "y_test = patient_test[\"SOURCE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess features\n",
    "numeric_feats = X_train.select_dtypes('number').columns.to_list()\n",
    "numeric_transformer = make_pipeline(StandardScaler())\n",
    "\n",
    "categorical_binary_feats = [\"SEX\"]\n",
    "categorical_binary_transformer = make_pipeline(OneHotEncoder(drop=\"if_binary\", dtype=int))\n",
    "\n",
    "preprocessor = make_column_transformer((numeric_transformer, numeric_feats),\n",
    "                                       (categorical_binary_transformer, categorical_binary_feats)\n",
    "                                       )\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time           0.004124\n",
       "score_time         0.014069\n",
       "test_accuracy      0.516296\n",
       "train_accuracy     0.513318\n",
       "test_precision     0.406146\n",
       "train_precision    0.396941\n",
       "test_recall        0.424699\n",
       "train_recall       0.392079\n",
       "test_f1            0.415214\n",
       "train_f1           0.394495\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating DummyClassifier as a baseline model to compare estimators to\n",
    "scoring = {'accuracy': 'accuracy',\n",
    "           'precision': make_scorer(precision_score, pos_label='in'),\n",
    "           'recall': make_scorer(recall_score, pos_label='in'),\n",
    "           'f1': make_scorer(f1_score, pos_label='in') }\n",
    "\n",
    "dummy_classifier = DummyClassifier(strategy = \"stratified\", random_state = 12)\n",
    "\n",
    "dummy_scores = pd.DataFrame(\n",
    "    cross_validate(\n",
    "        dummy_classifier, X_train, y_train, cv = 5, return_train_score = True, scoring = scoring\n",
    "    )\n",
    ")\n",
    "\n",
    "dummy_mean = dummy_scores.mean()\n",
    "dummy_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_cv_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.764169</td>\n",
       "      <td>0.740157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_neighbors  mean_train_score  mean_cv_score\n",
       "18           19          0.764169       0.740157"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN\n",
    "# find the k value that yields the best accuracy estimate\n",
    "results_dict = {\n",
    "    \"n_neighbors\": [],\n",
    "    \"mean_train_score\": [],\n",
    "    \"mean_cv_score\": []}\n",
    "\n",
    "for n in range(1,21):\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=n)\n",
    "    cv_scores = cross_validate(knn_model, X_train, y_train, cv=5, return_train_score=True)\n",
    "    results_dict[\"n_neighbors\"].append(n)\n",
    "    results_dict[\"mean_train_score\"].append(cv_scores[\"train_score\"].mean())\n",
    "    results_dict[\"mean_cv_score\"].append(cv_scores[\"test_score\"].mean())\n",
    "\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "\n",
    "results_df.sort_values(by=[\"mean_cv_score\"], ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_k = int(results_df.loc[results_df['mean_cv_score'].idxmax()]['n_neighbors'])\n",
    "best_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, 19 is the best k value in range 0-20 and yields a cross validation score of 74%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7304643261608154"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make new model with best k\n",
    "best_model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "\n",
    "# retrain classifier\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# get predictions on test data\n",
    "best_model.predict(X_test)\n",
    "\n",
    "# get estimate of accuracy of classifier on test data\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the knn classifier with k=19 is 73%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classification_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
